\documentclass[a4paper, 11pt]{article}
\usepackage{comment} % enables the use of multi-line comments (\ifx \fi) 
\usepackage{fullpage} % changes the margin
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{amsmath}
\usepackage{amsfonts}



\begin{document}
\noindent
\large\textbf{Final Exam} \hfill \textbf{Yen-Lin Chen} \\
\normalsize ECE 5412 \hfill yc2253@cornell.edu \\
Fall 2019 \hfill Due: 12/20/19 11 am\\

\section*{Question 1}
\subsection*{1(a)}





\subsection*{1(b)}
Since we know that the Markov Chain $s[k]$ has two states: $+1$ and $-1$, it suffices to compute $p(s[k]=1)$. We know the sensor model $y[k] = s[k] + A\sin(wk) + n[k]$ so we have the following conditional probability on measurement. 
\begin{equation}
p(y[k]|s[k]) = \frac{1}{\sqrt{2\pi}}\exp\left[-\frac{1}{2}\left(y[k] - s[k] - A\sin(wk) \right)^2 \right]
\end{equation}
To derive the optimal filter equations, we start with the state at time $k$: $p(s[k]=1)$ and use Chapman-Kolmogorov equation to obtain the prior at time $k+1$. 
\begin{equation}
p(s[k+1]|y[1:k]) = \sum_{s[k]\in \{+1, -1\}} p(s[k+1]|s[k])p(s[k])
\end{equation}
\begin{equation}
\begin{split}
p(s[k+1]=1|y[1:k]) & = p(s[k+1]=1|s[k]=1)p(s[k]=1) + p(s[k+1]=1|s[k]=-1)p(s[k]=-1) \\
 & = 0.8 p(s[k]=1) + 0.2(1 - p(s[k]=1)) \\ 
 & = 0.2 + 0.6 p(s[k]=1)
\end{split}
\end{equation}
And $p(s[k+1]=-1|y[1:k]) = 1- p(s[k+1]=1|y[1:k]) = 0.8 - 0.6 p(s[k]=1)$. Next, we apply Bayes rule to derive $p(s[k+1]=1|y[1:k+1])$. 
\begin{equation}
\begin{split}
 & p(s[k+1]=1|y[1:k+1]) = \frac{p(y[k+1]|s[k+1]=1)p(s[k+1]=1|y[1:k])}{\sum_{s[k+1]\in \{+1, -1\}}p(y[k+1]|s[k+1])p(s[k+1]|y[1:k])}\\
 & = \frac{p(s[k+1]=1|y[1:k])\exp\left[-\frac{1}{2}\left(y[k+1] - s[k+1] - A\sin(w(k+1)) \right)^2 \right]}{\sum_{s[k+1]\in \{+1, -1\}}p(s[k+1]|y[1:k])\exp\left[-\frac{1}{2}\left(y[k+1] - s[k+1] - A\sin(w(k+1)) \right)^2 \right]} \\ 
 & = p(s[k+1]=1)
\end{split}
\end{equation}
Eq. (3-4) are the optimal filter equations. 



\subsection*{1(c)}

\begin{figure}
	\begin{center}
		\includegraphics[width=6.5in]{q1c.png}
		\caption{Question 1(c): (Top) The simulated sensor measurements from the model with $A = 2.5$, $w = 2\pi/60$ and the filtered estimate at every time point using the optimal filter equations. (Bottom) The difference between the measurements and the filtered estimate. The mean-square-error is $0.63$ in this case. }
	\end{center}
	\label{fig:q1c}
\end{figure}

We simulated 1000 sensor measurements and then implemented the optimal filter from part (b) and the traces are shown in the top of Fig. 1. The difference between the measurements and filtered estimates is shown in the bottom of Fig. 1 with the mean-square-error of $0.63$.  



\subsection*{1(d)}

We repeated the process of part (c) for 50 times and found the mean-square-error of the filtered estimate to be $0.623$ with standard deviation of $0.036$. The low standard deviation suggests that the optimal filter is stable. We also found that the mean-square-error increases with smaller amplitude $A$ because the noise is on the same scale and the Markov Chain becomes difficult to uncover.  











\section*{Question 2}
\subsection*{2(a)}


\begin{figure}
	\begin{center}
		\includegraphics[width=6.5in]{q2a.png}
		\caption{Question 2(a): The PDF and CDF from Metropolis-Hastings simulation and true function. }
	\end{center}
	\label{fig:q2a}
\end{figure}

We would like to simulate the following PDF using the random-walk Metropolis-Hastings (MH) algorithm. 
\begin{equation}
\pi(x) \propto \cos^2(x)\sin^2(2x)\psi(x) \quad \psi(x) = \mathcal{N}(0,1)
\end{equation}
The random-walk MH algorithm is implemented as the following steps. 
\begin{enumerate}
\item Given $x_k$, We use the symmetric Gaussian kernel to generate $x_{k+1}$, i.e. $x_{k+1}\sim\mathcal{N}(x_k, 1)$. 
\item Calculate the acceptance ratio $r$. 
\begin{equation}
r = \frac{\cos^2(x_{k+1})\sin^2(2x_{k+1})\psi(x_{k+1})}{\cos^2(x_k)\sin^2(2x_k)\psi(x_k)}
\end{equation}
\item Generate $u\sim [0,1]$ and accept $x_{k+1}$ if $u < r$ or go back to step 1. 
\end{enumerate}
The simulated PDF and CDF are shown in Fig. \ref{fig:q2a}. 






\end{document}
